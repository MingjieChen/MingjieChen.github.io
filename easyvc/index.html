<!DOCTYPE html>
<html>
  <head>
    <title>EasyVC: A Toolkit for Any-to-Any Encoder-Decoder Voice Conversion Systems</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="helper.js" defer></script>
    <style>
      td {
        vertical-align: middle;
      }
      audio {
        width: 10vw;
        min-width: 100px;
        max-width: 250px;
      }
    </style>
  </head>
  <body>
    <div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
      <div class="text-center">
        <h1>EasyVC: A Toolkit for Any-to-Any Encoder-Decoder Voice Conversion Systems</h1>
        <!-- <p class="lead fw-bold">
          |<a
            href="https://arxiv.org/abs/2302.03540"
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p> -->
        <p>


        </p>
        <!-- <p class="fst-italic mb-0">
          Eugene Kharitonov, Damien Vincent,  Zalán Borsos, Raphaël Marinier, Sertan Girgin, Olivier Pietquin,
          Matt Sharifi, Marco Tagliasacchi, Neil Zeghidour
        </p> -->
        <p><b>Mingjie Chen, Thomas Hain</b></p>
        <p>Department of Computer Science, University of Sheffield</p>
      </div>
      <p>
        <b>Abstract.</b> 
        Current state-of-the-art voice conversion (VC) systems typically are developed based on an encoder-decoder framework. In this framework, encoders are used to extract linguistic, speaker or prosodic features from speech, then a decoder is to generate speech from speech features. Recently, there have been more and more advance models deployed as encoders or decoders for VC. Although obtaining good performance, the effects of these encoders and decoders have not been fully studied. On the other hand, VC technologies have been applied in different scenarios, which brings a lot of challenges for VC techiques. Hence, studies and understandings of encoders and decoders are becoming necessary and important. However, due to the complexity of VC systems, it is not always easy to compare and analyse these encoders and decoders. This paper introduces a toolkit, EasyVC, which is built upon the encoder-decoder framework. EasyVC supports a number of encoders and decoders within a unified framework, which makes it easy and convenient for VC training, inference, evaluation and deployment. EasyVC provides step-wise recipes covering from dataset downloading to objective evaluations and online demo presentation. Furthermore, EasyVC focuses on challenging VC scenarios such as one-shot, emotional, singing and real-time, which have not bee fully studied at the moment. EasyVC could help researchers and developers to investigate modules of VC systems and also promote the development of VC techniques.


      </p>
    </div>

<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="Encoder-Decoder Voice Conversion Framework" style="text-align: center;">Encoder-Decoder Voice Conversion Framework</h2>
    <div>
    <p><br/></p>
    <p style="text-align: center;">
        <img src="framework.png" height="200" width="1050" class="img-fluid">
    </p>
    <p><br/></p>
  </div>
        <p>
        Here we introduces the encoder-decoder framework for VC systems. As show in the figure, this framework typically is composed of three encoders, a decoder and a vocoder.
        More specifically, three encoders are used to extract representations from speech, including a linguistic encoder, a prosodic encoder and a speaker encoder. Then a decoder is used to reconstruct speech mel-spectrograms. Finally, a vocoder converts mel-spectrograms to waveforms. Note that this repo also supports decoders that directly reconstruct waveforms (e.g. VITS), in these case, vocoders are not needed.
        <!-- add framework descriptions-->
        </p>
</div>

<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="model-overview" style="text-align: left;">Table of Contents</h2>
    <div>
    <p style="text-align: left;">
    <ul style="list-style: outside none none !important;">
       <li><a href="#vc_exp_1" class="btn border-white bg-white fw-bold">One-shot Voice Conversion Results</a></li>
    </ul>
    </p>
  </div>
</div>



    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>One-shot Voice Conversion Results<a id="vc_exp_1"/></h3>

      <p style="margin-top: 2em">
        In this section, we provide the objective results and audio demos of a simple comparison one-shot VC experiment. We chosed VQ-Wav2vec and ConformerPPG as linguistic encoders, in the meantime, we chosed FastSpeech2, TacoAR and TacoMOL as decoders. Traing dataset is LibriTTS-460-clean, testing dataset is VCTK. We use d-vector as speaker encoder, ppgvc_f0 as prosodic encoder, ppgvc_hifigan as vocoder.
     </p>

     <p> <b>List VC Systems:</b></p>
     <li><b>System 0</b>: libritts_vqwav2vec_uttdvec_ppgvcf0_fs2_ppgvchifigan</li>    
     <li><b>System 1</b>: libritts_vqwav2vec_uttdvec_ppgvcf0_tacoar_ppgvchifigan</li>    
     <li><b>System 2</b>: libritts_vqwav2vec_uttdvec_ppgvcf0_tacomol_ppgvchifigan</li>    
     <li><b>System 3</b>: libritts_conformerppg_uttdvec_ppgvcf0_fs2_ppgvchifigan</li>    
     <li><b>System 4</b>: libritts_conformerppg_uttdvec_ppgvcf0_tacoar_ppgvchifigan</li>    
     <li><b>System 5</b>: libritts_conformerppg_uttdvec_ppgvcf0_tacomol_ppgvchifigan</li>    

        
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="voice-conversion-exp-table"
        >
          <thead>
            <tr>
              <th style="text-align: center" >Source Audio</th>
              <th style="text-align: center">Target Audio</th>
              <th style="text-align: center">System 0</th>
              <th style="text-align: center">System 1</th>
              <th style="text-align: center">System 2</th>
              <th style="text-align: center">System 3</th>
              <th style="text-align: center">System 4</th>
              <th style="text-align: center">System 5</th>
            </tr>
          </thead>
          <tbody>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=80px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

    </div>




  </body>
</html>
