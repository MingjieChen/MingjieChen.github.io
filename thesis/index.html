<!DOCTYPE html>
<html>
  <head>
    <title>Demo Page</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="helper.js" defer></script>
    <style>
      td {
        vertical-align: middle;
      }
      audio {
        width: 20vw;
        min-width: 100px;
        max-width: 250px;
      }
    </style>
  </head>
  <body>
    <div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
      <div class="text-center">
        <h1>Audio demos for thesis: "Disentanglement Learning for Text-Free Voice Conversion"</h1>
        <!-- <p class="lead fw-bold">
          |<a
            href="https://arxiv.org/abs/2302.03540"
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p> -->
        <p>


        </p>
        <!-- <p class="fst-italic mb-0">
          Eugene Kharitonov, Damien Vincent,  Zalán Borsos, Raphaël Marinier, Sertan Girgin, Olivier Pietquin,
          Matt Sharifi, Marco Tagliasacchi, Neil Zeghidour
        </p> -->
        <p><b>Mingjie Chen, University of Sheffield</b></p>
      </div>
      <p>
        <b>Introduction </b>  
        This thesis aims to study disentanglement learning methods for Voice Conversion (VC). This demo page presents audio demos from three experiments of this thesis. The first experiment studies VQ-WAE, IN-WAE, WAE and SVQ-WAE models on a many-to-many VC task on VCTK dataset. The second experiment focuses on comparing model performance robustness of WAGAN-VC and baseline models. The third experiment explore four types of systems composing different linguistic encoder and decoder on three VC tasks. Details of experiment setups will be introduced in each experiment part.

      </p>
    </div>

<!--<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="model-overview" style="text-align: center;">Make-A-Voice Overview</h2>
    <div>
    <p><br/></p>
    <p style="text-align: center;">
        <img src="arch.png" height="200" width="1050" class="img-fluid">
    </p>
    <p><br/></p>
  </div>
        <p>
          Make-A-Voice is considered a unified voice synthesis framework with a "coarse-to-fine" design that progressively enhances the modeling of voice signals by injecting desired conditioning information, which is organized in three main stages as illustrated in Figure 1: 1) semantic stage <i>S<sub>1</sub></i>, speech or text inputs are transformed into a sequence of semantic tokens <i>s</i>, 2) acoustic stage <i>S<sub>2</sub></i>, acoustic tokens <i>a</i> with a variety of conditions (speaker, emotion, prosody, and style) are generated autoregressively from the "pseudo" text (i.e., semantic tokens <i>s</i>); 3) generation stage <i>S<sub>3</sub></i>, a unit-based vocoder synthesizes high-fidelity waveforms from compressed acoustic representations.
        </p>
</div>
-->
<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="model-overview" style="text-align: left;">Table of Contents</h2>
    <div>
    <p style="text-align: left;">
    <ul style="list-style: outside none none !important;">
       <li><a href="#exp1" class="btn border-white bg-white fw-bold">Experiment 1</a></li>
       <li><a href="#exp2" class="btn border-white bg-white fw-bold">Experiment 2</a></li>
       <li><a href="#exp3" class="btn border-white bg-white fw-bold">Experiment 3</a></li>
       
    </ul>
    </p>
  </div>
</div>


    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Experiment 1<a id="exp1"/></h3>

      <p style="margin-top: 2em">
        In this experiment, we provide audio samples from two proposed models (IN-WAE, SVQ-WAE) and two baseline models (WAE and VQ-WAE). 
              </p>
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp1-table"
        >
          <thead>
            <tr>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">VQ-WAE</th>
              <th style="text-align: center">WAE</th>
              <th style="text-align: center">IN-WAE</th>
              <th style="text-align: center">SVQ-WAE</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=150px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=150px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=150px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=150px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

    </div>

    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Experiment 2<a id="exp2"/></h3>

      <p style="margin-top: 2em">
        In this experiment, three models (StarGAN-VC, StarGAN-VC2 and WAGAN-VC) are studied under two sessions. Session 1 explores six training data situations with varying <b>numbers of speakers (N)</b> and <b>numbers of training sample per speaker (M)</b>, while keeping a fixing number of training samples. Session 2 explores four training data situations with a fixing number of speakers and decreasing numbers of training samples per speakers.
              </p>

      <h3>Session1: exploring number of speakers N and number of training samples per speaker M</h3>        
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp2-sess1-table"
        >
          <thead>
            <tr>
              <th style="text-align: center;">N</th>
              <th style="text-align: center;">M</th>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">StarGAN-VC</th>
              <th style="text-align: center">StarGAN-VC2</th>
              <th style="text-align: center">WAGAN-VC</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=100px> <td>109</td> <td>35</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>90</td> <td>40</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>60</td> <td>60</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>40</td> <td>90</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>20</td> <td>180</td><td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>10</td> <td>360</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

      <h3>Session2: decreasing number of training samples per speaker M</h3>        
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp2-sess2-table"
        >
          <thead>
            <tr>
              <th style="text-align: center;">N</th>
              <th style="text-align: center;">M</th>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">StarGAN-VC</th>
              <th style="text-align: center">StarGAN-VC2</th>
              <th style="text-align: center">WAGAN-VC</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=100px> <td>109</td> <td>35</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>109</td> <td>20</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>109</td> <td>10</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td>109</td> <td>5</td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

    </div>

    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Experiment 3<a id="exp3"/></h3>

      <p style="margin-top: 2em">
        In this section, four encoder-decoder VC systems are compared on three VC tasks. We firstly present the four VC systems with different linguistic encoders and different decoders. Then we present audio demos on three VC tasks, including a many-to-many VC task on VCTK, a intral-lingual one-shot VC task on VCC2020 and a cross-lingual one-shot VC task on VCC2020.
              </p>
      <div>
        <table class="table table-hover">
          <thead>
            <tr>
              <th>System index</th>
              <th>Linguistic encoder</th>
              <th>Decoder</th>
            </tr>
          </thead>
          <tbody>
            <tr> <td>Sys-1</td> <td>VQ-Wav2vec</td> <td>Taco-AR</td></tr>
            <tr> <td>Sys-2</td> <td>VQ-Wav2vec</td> <td>FastSpeech</td></tr>
            <tr> <td>Sys-3</td> <td>ASR-BNE</td> <td>Taco-AR</td></tr>
            <tr> <td>Sys-1</td> <td>ASR-BNE</td> <td>FastSpeech</td></tr>
          </tbody>

        </table>
      </div>        
      <h3>Session1: many-to-many VC on VCTK</h3>
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp3-sess1-table"
        >
          <thead>
            <tr>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">Sys-1</th>
              <th style="text-align: center">Sys-2</th>
              <th style="text-align: center">Sys-3</th>
              <th style="text-align: center">Sys-4</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

      <h3>Session2: intra-ligual one-shot VC on VCTK</h3>
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp3-sess2-table"
        >
          <thead>
            <tr>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">Sys-1</th>
              <th style="text-align: center">Sys-2</th>
              <th style="text-align: center">Sys-3</th>
              <th style="text-align: center">Sys-4</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

      <h3>Session3: cross-ligual one-shot VC on VCTK</h3>
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="exp3-sess3-table"
        >
          <thead>
            <tr>
              <th style="text-align: center">Source</th>
              <th style="text-align: center">Target</th>
              <th style="text-align: center">Sys-1</th>
              <th style="text-align: center">Sys-2</th>
              <th style="text-align: center">Sys-3</th>
              <th style="text-align: center">Sys-4</th>
            </tr>
          </thead>
          <tbody>
             <!-- <tr>
               <td colspan="4" style="text-align: center">LJSpeech (test set)</td>
             </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> </tr>
            -->
             <!-- <tr>
               <td colspan="4" style="text-align: center">LibriSpeech (test-clean)</td>
             </tr> -->
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
             <tr height=100px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td></tr>
          </tbody>
        </table>
      </div>

    </div>

    

    </div>


    <!-- <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Broader impact<a id="impact"/></h3>
      <p class="mb-0">
      We believe our work on high-quality TTS that requires very limited supervision (quantity- and quality-wise) can be an important stepping stone for enabling this core speech technology for communities that are currently underserved by TTS solutions due to speaking "low-resource" languages, i.e., languages do not have vast parallel corpora required for training deep learning models. Even for high-resource languages, such as English, the ability to harness unpaired data for speech generation can enable producing speech in accents and dialects that are currently uncovered by the existing TTS systems.
      </p>
      <br />
      <p>
      At the same time, we acknowledge that the ability to mimic a voice can have numerous malicious applications, including bypassing biometric identification for the purpose of impersonation. Thus it is crucial to put safeguards against the misuse of SPEAR-TTS and, as an initial step, we verify that speech produced by SPEAR-TTS can be reliably detected by a classifier (see Appendix E). In the future, one can explore other approaches for detecting synthesized speech, for example by audio watermarking.
     </p>
    </div> -->


  </body>
</html>
